import sys
import re
import argparse
from tqdm import tqdm

# K√Ω t·ª± ƒë·∫∑c bi·ªát c·ªßa SentencePiece (U+2581)
# Code c·ªßa b·∫°n d√πng spm m·∫∑c ƒë·ªãnh n√™n ch·∫Øc ch·∫Øn s·∫Ω c√≥ k√Ω t·ª± n√†y trong output
SP_SPACE = u'\u2581' 

class PostProcessor:
    def __init__(self, lang):
        self.lang = lang

    def decode_sentencepiece(self, text):
        """
        B∆∞·ªõc 1: N·ªëi c√°c m·∫£nh BPE l·∫°i chu·∫©n x√°c theo logic c·ªßa SentencePiece.
        Input: " T √¥i  y √™u  Vi·ªát  Nam" (C√≥ k√Ω t·ª± SP_SPACE)
        Output: "T√¥i y√™u Vi·ªát Nam"
        """
        text = text.strip()
        
        # N·∫øu output model ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát c·ªßa SentencePiece
        if SP_SPACE in text:
            # Logic: Thay th·∫ø SP_SPACE b·∫±ng kho·∫£ng tr·∫Øng, x√≥a kho·∫£ng tr·∫Øng th·ª´a
            text = text.replace(" ", "")      # X√≥a kho·∫£ng tr·∫Øng ngƒÉn c√°ch token
            text = text.replace(SP_SPACE, " ") # Thay k√Ω t·ª± SP b·∫±ng d·∫•u c√°ch th∆∞·ªùng
        else:
            # Fallback: N·∫øu model output kh√¥ng c√≥ k√Ω t·ª± SP (hi·∫øm, nh∆∞ng ph√≤ng h·ªù)
            # Gi·∫£ ƒë·ªãnh gh√©p ƒë√¥i @@ (n·∫øu d√πng BPE c·ªï ƒëi·ªÉn) ho·∫∑c gh√©p th·∫≥ng
            text = text.replace("@@ ", "")
            # N·∫øu kh√¥ng c√≥ d·∫•u hi·ªáu g√¨, t·∫°m th·ªùi n·ªëi li·ªÅn ho·∫∑c gi·ªØ nguy√™n t√πy case
            # V·ªõi pipeline c·ªßa b·∫°n, 99% s·∫Ω r∆°i v√†o case 'if' ·ªü tr√™n.
            pass
            
        return text.strip()

    def post_process_vietnamese(self, text):
        """
        X·ª≠ l√Ω ri√™ng cho Ti·∫øng Vi·ªát (Output t·ª´ PyVi)
        Input: "T√¥i ƒëang h·ªçc t·∫°i ƒê·∫°i_h·ªçc B√°ch_Khoa ."
        Output: "T√¥i ƒëang h·ªçc t·∫°i ƒê·∫°i h·ªçc B√°ch Khoa."
        """
        # 1. Quan tr·ªçng nh·∫•t: X√≥a d·∫•u g·∫°ch d∆∞·ªõi do PyVi sinh ra
        text = text.replace("_", " ")
        
        return text

    def post_process_scriptio_continua(self, text):
        """
        X·ª≠ l√Ω cho Ti·∫øng Trung, L√†o, Khmer (C√°c ng√¥n ng·ªØ vi·∫øt li·ªÅn)
        V·∫•n ƒë·ªÅ: Tokenizer (Jieba, LaoNLP) ƒë√£ ch√®n d·∫•u c√°ch v√†o gi·ªØa c√°c t·ª´.
        Nhi·ªám v·ª•: X√≥a d·∫•u c√°ch ƒë·ªÉ vƒÉn b·∫£n li·ªÅn m·∫°ch tr·ªü l·∫°i.
        """
        # Logic: Ch·ªâ x√≥a kho·∫£ng tr·∫Øng n·∫øu 2 b√™n l√† k√Ω t·ª± c·ªßa ng√¥n ng·ªØ ƒë√≥.
        # Gi·ªØ l·∫°i kho·∫£ng tr·∫Øng n·∫øu l√† Ti·∫øng Anh ho·∫∑c S·ªë n·∫±m gi·ªØa.
        
        if self.lang == 'zh': # Ti·∫øng Trung
            # T√¨m: (Ch·ªØ H√°n) space (Ch·ªØ H√°n) -> X√≥a space
            pat = re.compile(r'(?<=[\u4e00-\u9fa5])\s+(?=[\u4e00-\u9fa5])')
            text = pat.sub('', text)
            
        elif self.lang in ['lo', 'km']: # L√†o / Khmer
            # V·ªõi L√†o/Khmer, vi·ªác x√≥a to√†n b·ªô space kh√° r·ªßi ro v√¨ space ƒë√¥i khi l√† ng·∫Øt c√¢u.
            # Tuy nhi√™n, output c·ªßa machine translation th∆∞·ªùng tokenize qu√° ƒë√†.
            # Best practice an to√†n: X√≥a space tr∆∞·ªõc c√°c d·∫•u c√¢u ƒë·∫∑c bi·ªát
            text = re.sub(r'\s+([·üî·üï])', r'\1', text)
            
            # (T√πy ch·ªçn) N·∫øu b·∫°n mu·ªën output li·ªÅn t√π t√¨ nh∆∞ vƒÉn b·∫£n g·ªëc:
            # text = text.replace(" ", "") 
            # Nh∆∞ng t√¥i khuy√™n n√™n gi·ªØ nguy√™n logic BPE gh√©p l·∫°i, v√¨ model ƒë√£ h·ªçc c√°ch ƒë·∫∑t space.
            pass

        return text

    def fix_punctuation_and_capitalize(self, text):
        """B∆∞·ªõc l√†m ƒë·∫πp cu·ªëi c√πng (Cosmetics)"""
        # 1. X√≥a kho·∫£ng tr·∫Øng tr∆∞·ªõc d·∫•u c√¢u (vd: "H√† N·ªôi ." -> "H√† N·ªôi.")
        text = re.sub(r'\s+([.,;:?!])', r'\1', text)
        
        # 2. Th√™m kho·∫£ng tr·∫Øng sau d·∫•u c√¢u n·∫øu b·ªã d√≠nh (vd: "H√† N·ªôi.T√¥i" -> "H√† N·ªôi. T√¥i")
        # (Tr·ª´ tr∆∞·ªùng h·ª£p s·ªë th·∫≠p ph√¢n 3.5)
        text = re.sub(r'([.,;:?!])(?=[^\s\d])', r'\1 ', text)

        # 3. Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu c√¢u
        if text:
            text = text[0].upper() + text[1:]
            
        return text

    def run(self, text):
        # B∆Ø·ªöC 1: Gh√©p m·∫£nh (De-BPE)
        text = self.decode_sentencepiece(text)
        
        # B∆Ø·ªöC 2: X·ª≠ l√Ω ƒë·∫∑c th√π ng√¥n ng·ªØ
        if self.lang == 'vi':
            text = self.post_process_vietnamese(text)
        elif self.lang in ['zh', 'lo', 'km']:
            text = self.post_process_scriptio_continua(text)
            
        # B∆Ø·ªöC 3: Trang ƒëi·ªÉm (D·∫•u c√¢u + Vi·∫øt hoa)
        text = self.fix_punctuation_and_capitalize(text)
        
        return text

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="File k·∫øt qu·∫£ d·ªãch th√¥ (output c·ªßa model)")
    parser.add_argument("--output", required=True, help="File k·∫øt qu·∫£ ƒë·∫πp sau khi x·ª≠ l√Ω")
    parser.add_argument("--lang", required=True, choices=['vi', 'zh', 'lo', 'km', 'en'], help="Ng√¥n ng·ªØ ƒë√≠ch")
    args = parser.parse_args()

    print(f"üöÄ B·∫Øt ƒë·∫ßu Post-processing cho ng√¥n ng·ªØ: {args.lang.upper()}")
    
    processor = PostProcessor(lang=args.lang)
    count = 0
    
    with open(args.input, 'r', encoding='utf-8') as f_in, \
         open(args.output, 'w', encoding='utf-8') as f_out:
        
        for line in tqdm(f_in):
            if not line.strip():
                f_out.write("\n")
                continue
                
            processed_line = processor.run(line)
            f_out.write(processed_line + "\n")
            count += 1

    print(f"‚úÖ ƒê√£ x·ª≠ l√Ω xong {count} c√¢u.")
    print(f"üìÑ K·∫øt qu·∫£ l∆∞u t·∫°i: {args.output}")