# ==============================================================================
# CẤU HÌNH OPTIMIZED CHO GPU 8GB VRAM - DATASET 105K (VLSP)
# ==============================================================================

data:
  # Đảm bảo đường dẫn đúng tới file đã BPE
  train_data_location: data/Laos_bpe/train2023
  eval_data_location: data/Laos_bpe/dev2023
  src_lang: .bpe.lo 
  trg_lang: .bpe.vi 

# 1. MODEL PARAMETERS (Cấu hình Small-Base)
# Lý do: Với 105k câu, model quá to sẽ học vẹt (overfit).
# d_model=256 giúp model nhẹ, train nhanh gấp đôi model 512, vừa vặn 8GB VRAM.
d_model: 256
n_layers: 6
heads: 8        # Tăng lên 8 heads để học ngữ cảnh tốt hơn (256/8 = 32 dim/head)
d_ff: 1024      # Feed-forward network
dropout: 0.3  # Giữ 0.3 để tránh overfit với dữ liệu ít

# 2. TRAINING CONFIG (QUAN TRỌNG NHẤT CHO 8GB VRAM)
# Batch size 32 là mức an toàn cho 8GB với cấu hình model trên.
# Nếu bị lỗi OOM (hết bộ nhớ), hãy giảm xuống 16.
batch_size: 32 
accum_count: 4
eval_batch_size: 8

# 3. OPTIMIZER
# Với d_model 256, Learning rate nên cao hơn một chút để hội tụ nhanh
lr: 2.0             
optimizer: Adam
optimizer_params:
  betas: [0.9, 0.98]
  eps: !!float 1e-9
n_warmup_steps: 4000
label_smoothing: 0.1

# 4. QUẢN LÝ QUÁ TRÌNH TRAIN
epochs: 40                # 105k câu cần khoảng 40-50 epochs để đạt đỉnh
printevery: 500             # In log mỗi 500 bước
save_checkpoint_epochs: 1   # Lưu model mỗi 5 epochs (đỡ tốn dung lượng ổ cứng)
maximum_saved_model_eval: 5
maximum_saved_model_train: 5
train_max_length: 100 

# 5. CẤU HÌNH KHÁC
log_file_models: 'model_vlsp_8gb.log'
device: cuda           # Cố định hạt giống để kết quả tái lập được

# 6. INFERENCE (DỊCH THỬ)
decode_strategy: BeamSearch
decode_strategy_kwargs:
  beam_size: 5 
  length_normalize: 0.6 
input_max_length: 100
max_length: 100