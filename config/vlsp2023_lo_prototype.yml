# ==============================================================================
# CONFIG CHO VLSP 2023 (LAO-VIET) - 330K CÂU
# ==============================================================================

data:
  train_data_location: data/Laos_2023/train2023.token
  eval_data_location: data/Laos_2023/dev2023.token
  src_lang: .bpe.lo
  trg_lang: .bpe.vi

# 1. MODEL ARCHITECTURE (TRANSFORMER BASE)
d_model: 512
n_layers: 6
heads: 8
d_ff: 2048
dropout: 0.3      # Data trung bình (Medium), dropout 0.3 là chuẩn.

# 2. TRAINING CONFIG
batch_size: 16    
accum_count: 8    # Effective batch = 128. Khá tốt cho hội tụ.
eval_batch_size: 16

# 3. OPTIMIZER
optimizer: Adam
optimizer_params:
  betas: [0.9, 0.98]
  eps: !!float 1e-9

lr: 2.0        
n_warmup_steps: 4000
label_smoothing: 0.1

# 4. QUẢN LÝ
epochs: 150       # Set cao lên để Early Stopping tự quyết định (thực tế sẽ dừng tầm 40-60)
printevery: 100
save_checkpoint_epochs: 1
maximum_saved_model_eval: 5
maximum_saved_model_train: 5
train_max_length: 110 

# 5. EARLY STOPPING
patience: 10      # Quan trọng: Đợi 10 epoch không cải thiện mới dừng.

# 6. KHÁC
log_file_models: 'model_vlsp_lo_vi.log'
device: cuda

# 7. INFERENCE
decode_strategy: BeamSearch
decode_strategy_kwargs:
  beam_size: 1    # Beam=1 (Greedy) train nhanh. Khi test thật có thể tăng lên 4-5.
  length_normalize: 1.0
input_max_length: 110   
max_length: 110