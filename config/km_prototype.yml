# ==============================================================================
# CẤU HÌNH TRANSFORMER KHMER - VIETNAMESE (OPTIMIZED FOR 500K SENTENCES)
# ==============================================================================

data:
  # Thư mục chứa dữ liệu đã chạy BPE
  train_data_location: data/Khmer/train
  eval_data_location: data/Khmer/dev
  
  # LƯU Ý QUAN TRỌNG: 
  # Hãy kiểm tra file trong thư mục data/Khmer/train xem đuôi là gì.
  # Nếu bạn đã chạy run_bpe_km.py thì đuôi thường là .bpe.km và .bpe.vi
  src_lang: .bpe.km 
  trg_lang: .bpe.vi 

# 1. MODEL PARAMETERS (Cấu hình Base - Chuẩn mực cho 500k câu)
# Nâng cấp từ 256 lên 512 để đủ sức chứa ngữ nghĩa của 500.000 câu
d_model: 512
n_layers: 6
heads: 8        # 512 chia hết cho 8 (mỗi head 64 dim)
d_ff: 2048      # Mạng nơ-ron dày hơn để xử lý ngữ pháp Khmer phức tạp
dropout: 0.2    # Giảm từ 0.35 xuống 0.2 vì dữ liệu nhiều, ít sợ học vẹt hơn

# 2. TRAINING CONFIG (Tối ưu cho 8GB VRAM)
# Model to hơn nên phải giảm Batch Size để không cháy VRAM
batch_size: 16      # Mức an toàn cho 8GB với model Base
accum_count: 16      # Tích lũy 8 lần (Tương đương batch_size thực tế = 128)
eval_batch_size: 8    # Giữ nhỏ để tránh OOM khi validate

# 3. OPTIMIZER
lr: 2.0
optimizer: Adam       # Dùng Adam chuẩn cho ổn định
optimizer_params:
  betas: [0.9, 0.98]
  eps: !!float 1e-9
n_warmup_steps: 4000  # Warmup lâu hơn để model Base hội tụ tốt
label_smoothing: 0.1

# 4. QUẢN LÝ QUÁ TRÌNH TRAIN
epochs: 30            # 500k câu thì 30 epochs là đủ (chạy lâu đấy!)
printevery: 200    # In log thường xuyên
save_checkpoint_epochs: 1
maximum_saved_model_eval: 5
maximum_saved_model_train: 5
train_max_length: 100

# 5. KHÁC
log_file_models: 'model_km_base.log'
device: cuda
lowercase: false      # Tiếng Khmer không có chữ hoa/thường, nhưng tiếng Việt thì có -> False

# 6. INFERENCE (DỊCH THỬ)
decode_strategy: BeamSearch
decode_strategy_kwargs:
  beam_size: 5
  length_normalize: 0.6
  replace_unk: true
input_max_length: 100
max_length: 100