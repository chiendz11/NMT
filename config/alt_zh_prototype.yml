# ==============================================================================
# CONFIG TỐI ƯU CHO OPENSUBTITLES (ZH-VI) - 500K CÂU
# ==============================================================================

data:
  train_data_location: data/Chinese/train
  eval_data_location: data/Chinese/dev
  src_lang: .bpe.zh
  trg_lang: .bpe.vi

# 1. MODEL (BASE)
d_model: 512
n_layers: 6
heads: 8
d_ff: 2048
dropout: 0.3      # Subtitle rất nhiễu, giữ dropout 0.3 là chuẩn

# 2. TRAINING STRATEGY (TẬN DỤNG CÂU NGẮN)
# Vì câu chỉ dài trung bình 9 token, ta có thể nhồi Batch cực lớn
batch_size: 96    # TĂNG LÊN 96 (GPU 8GB chịu tốt vì max_len thấp)
accum_count: 1    # Giảm accum xuống 1 vì batch 96 đã đủ lớn để học tốt rồi.
                  # Train sẽ mượt hơn rất nhiều.
eval_batch_size: 32

# 3. OPTIMIZER
optimizer: Adam
optimizer_params:
  betas: [0.9, 0.98]
  eps: !!float 1e-9

lr: 0.0003        # LR chuẩn cho Batch lớn
n_warmup_steps: 4000 
label_smoothing: 0.1

# 4. QUẢN LÝ
epochs: 30
printevery: 100
save_checkpoint_epochs: 1
maximum_saved_model_eval: 5
maximum_saved_model_train: 5
train_max_length: 40  # CHỐT HẠ: 99% data < 29 tokens. 
                      # Để 40 là bao trọn vẹn, cắt bỏ phần rác siêu dài (nếu có).

# 5. KHÁC
log_file_models: 'model_zh_vi_base.log'
device: cuda

# 6. INFERENCE
decode_strategy: BeamSearch
decode_strategy_kwargs:
  beam_size: 5
  length_normalize: 1.0
input_max_length: 40    # Khớp với train
max_length: 40